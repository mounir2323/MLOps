# # ml_pipeline/assets/training.py
# import mlflow as mlflow_module  # Importation du module mlflow avec un alias
# import mlflow.sklearn
# import mlflow.xgboost

# from xgboost import XGBClassifier
# import dagster as dg
# from ml_pipeline.resources.mlflow import MLflowTracking
# import pandas as pd

# @dg.asset
# def trained_model(context: dg.AssetExecutionContext, split_data: pd.DataFrame, mlflow: MLflowTracking):
#     # Solution 2 : split_data est un DataFrame avec une colonne 'split'
#     train = split_data[split_data["split"] == "train"]
#     X_train = train.drop(["popularity", "split"], axis=1)
#     y_train = train["popularity"]
    
#     # Configuration de MLflow avant de cr√©er le mod√®le
#     mlflow.setup_context()
    
#     model = XGBClassifier(
#         objective="binary:logistic",  # Objectif plus appropri√© pour XGBoost (au lieu de class_weight)
#         eval_metric="logloss",
#         use_label_encoder=False,
#         random_state=42
#     )
    
#     context.log.info("Auto-logging is enabled for XGBoost.")
    
#     # Utilisation de la ressource mlflow pour d√©marrer un run
#     with mlflow.start_run(run_name="train_XGBC") as run:
#         # Log explicite des param√®tres pour s'assurer qu'ils sont captur√©s
#         mlflow_module.log_param("model_type", "XGBClassifier")
#         mlflow_module.log_param("features_count", len(X_train.columns))
        
#         # Cr√©er un ensemble de validation pour l'√©valuation pendant l'entra√Ænement
#         from sklearn.model_selection import train_test_split
#         X_train_split, X_val, y_train_split, y_val = train_test_split(
#             X_train, y_train, test_size=0.2, random_state=42
#         )
#         eval_set = [(X_val, y_val)]
        
#         # Entra√Ænement avec verbose et eval_set pour capturer les m√©triques d'entra√Ænement
#         model.fit(
#             X_train_split, 
#             y_train_split,
#             eval_set=eval_set,
#             verbose=True
#         )
        
#         # Log manuel de quelques m√©triques d'√©valuation pour s'assurer qu'elles sont captur√©es
#         import numpy as np
#         val_pred = model.predict(X_val)
#         val_accuracy = np.mean(val_pred == y_val)
#         mlflow_module.log_metric("validation_accuracy", val_accuracy)

#     return model



import pandas as pd
import dagster as dg
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
import mlflow
import mlflow.xgboost

@dg.asset(io_manager_key="io_manager", required_resource_keys={"mlflow"})
def trained_model(context: dg.AssetExecutionContext, split_data):
    """Entra√Æne un mod√®le XGBoost avec MLflow autolog."""
    
    # R√©cup√©rer la ressource MLflow et configurer le tracking
    mlflow_resource = context.resources.mlflow
    mlflow_resource.setup_context()
    
    # D√©marrer un run MLflow avec la ressource configur√©e
    with mlflow_resource.start_run(run_name=f"spotify_pipeline_{context.run_id[:8]}") as run:
        # Activer l'autolog XGBoost (fait tout automatiquement)
        mlflow.xgboost.autolog(
            log_input_examples=True,
            log_model_signatures=True,
            log_models=True,
        )
        
        # Tags personnalis√©s seulement (pas logg√©s automatiquement)
        mlflow.set_tags({
            "pipeline.stage": "training",
            "model.type": "xgboost", 
            "data.version": "v1",
            "dagster.run_id": context.run_id,
            "dagster.asset_name": "trained_model"
        })
        
        # Extraire les donn√©es
        train_data = split_data[split_data["split"] == "train"]
        test_data = split_data[split_data["split"] == "test"]
        
        X_train = train_data.drop(["popularity", "split"], axis=1)
        y_train = train_data["popularity"]
        X_test = test_data.drop(["popularity", "split"], axis=1)
        y_test = test_data["popularity"]
        
        context.log.info(f"üèãÔ∏è Entra√Ænement sur {len(X_train)} √©chantillons")
        context.log.info(f"üîç Test sur {len(X_test)} √©chantillons")
        
        # Cr√©er et entra√Æner le mod√®le (autolog capture tout automatiquement)
        model = XGBClassifier(
            objective='binary:logistic',
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42,
            eval_metric='logloss'
        )
        
        # L'entra√Ænement avec eval_set - autolog capture les m√©triques automatiquement
        model.fit(
            X_train, y_train,
            eval_set=[(X_train, y_train), (X_test, y_test)],
            verbose=False
        )
        
        context.log.info("‚úÖ Mod√®le entra√Æn√© avec autolog MLflow activ√©")
        
        return {
            'model': model,
            'X_test': X_test,
            'y_test': y_test,
            'mlflow_run_id': run.info.run_id
        }